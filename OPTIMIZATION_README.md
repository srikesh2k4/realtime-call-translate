# ðŸŒ Real-Time Two-Way Live Call Translation

A highly optimized real-time speech translation system that enables two-way communication between speakers of different languages (English â†” Hindi).

## ðŸš€ Key Optimizations

### 1. **Low Latency Architecture**
- **Smart VAD-based Segmentation**: Instead of fixed windows, the system detects natural speech boundaries
- **Reduced Processing Windows**: 500ms minimum, 15s maximum (down from 2.5s fixed)
- **Silence Detection**: 600ms silence triggers end-of-utterance processing
- **Parallel Processing**: Audio relay and ML processing happen concurrently

### 2. **Advanced Speech Recognition**
- **faster-whisper**: CTranslate2-based Whisper for 4x faster inference
- **Model Options**:
  - `distil-large-v3`: Best balance of speed and accuracy (recommended)
  - `large-v3`: Highest accuracy for complex speech
  - `medium`: Good for lower-end hardware
- **Built-in VAD**: Whisper's VAD filter prevents hallucinations

### 3. **Noise Suppression (3 Layers)**
1. **Browser Level**: WebRTC echoCancellation, noiseSuppression, autoGainControl
2. **Audio Worklet**: Adaptive noise gate with envelope smoothing
3. **ML Backend**: noisereduce library for stationary noise removal

### 4. **Anti-Hallucination System**
- Strict transcript validation
- Minimum word count requirements
- Repetition detection
- Filler word filtering
- Confidence threshold (>30%)

### 5. **Long Conversation Support**
- Smart chunking for speeches up to 15 seconds
- Overlap preservation for continuity
- Conversation history tracking
- Translation caching

## ðŸ“Š Performance Metrics

| Metric | Before | After |
|--------|--------|-------|
| Minimum Latency | 2.5s | ~500ms |
| Max Speech Duration | 2.5s | 15s |
| Hallucination Rate | High | <1% |
| Noise Handling | Basic | 3-layer |

## ðŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend   â”‚â”€â”€â”€â”€â–¶â”‚  Go Backend  â”‚â”€â”€â”€â”€â–¶â”‚  ML Worker   â”‚
â”‚   (React)    â”‚â—€â”€â”€â”€â”€â”‚  (WebSocket) â”‚â—€â”€â”€â”€â”€â”‚  (FastAPI)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚                     â”‚                    â”‚
      â”‚                     â”‚                    â”‚
  Audio Worklet        Room Manager         faster-whisper
  Noise Gate           VAD Detection        Silero VAD
  Browser NS           Audio Relay          noisereduce
                                           GPT-4.1-mini
                                           OpenAI TTS
```

## ðŸ› ï¸ Setup

### Prerequisites
- Docker & Docker Compose
- NVIDIA GPU (recommended) or CPU
- OpenAI API Key

### Environment Variables
Create `.env` file in `ml-python/`:
```env
OPENAI_API_KEY=your_api_key_here
```

### Running with Docker
```bash
docker-compose up --build
```

### Running Locally

**ML Worker (Python):**
```bash
cd ml-python
pip install -r requirements.txt
uvicorn worker:app --host 0.0.0.0 --port 9001
```

**Go Backend:**
```bash
cd backend-go
go mod tidy
go run main.go
```

**Frontend:**
```bash
cd frontend
npm install
npm run dev
```

## ðŸ”§ Configuration

### ML Worker (`worker.py`)
```python
@dataclass
class Config:
    SAMPLE_RATE: int = 16000
    MIN_SPEECH_MS: int = 300        # Min speech to process
    MAX_SPEECH_MS: int = 15000      # Max before forced processing
    SILENCE_THRESHOLD_MS: int = 600 # Silence = end of utterance
    VAD_THRESHOLD: float = 0.5      # Speech probability threshold
    WHISPER_MODEL: str = "distil-large-v3"  # ASR model
    NOISE_REDUCE: bool = True       # Enable noise reduction
```

### Go Backend (`main.go`)
```go
const (
    SAMPLE_RATE = 16000
    MIN_SAMPLES = SAMPLE_RATE / 2   // 500ms
    MAX_SAMPLES = SAMPLE_RATE * 15  // 15s
    SILENCE_THRESHOLD_SAMPLES = SAMPLE_RATE * 6 / 10  // 600ms
)
```

## ðŸŽ¯ Best Models for Production

### Speech Recognition (ASR)
| Model | Speed | Accuracy | VRAM | Use Case |
|-------|-------|----------|------|----------|
| `distil-large-v3` | Fast | High | ~3GB | **Recommended** |
| `large-v3` | Medium | Highest | ~6GB | Complex speech |
| `medium` | Faster | Good | ~2GB | Low-end GPU |
| `small` | Fastest | Moderate | ~1GB | CPU only |

### Translation
- **GPT-4.1-mini**: Fast, accurate, cost-effective
- **GPT-4o**: Highest quality for complex sentences

### Text-to-Speech
- **tts-1**: Fast, good quality (recommended)
- **tts-1-hd**: Highest quality, slower

## ðŸ” Troubleshooting

### High Latency
1. Check GPU utilization (`nvidia-smi`)
2. Reduce `WHISPER_MODEL` to smaller variant
3. Increase `SILENCE_THRESHOLD_MS`

### Hallucinations
1. Increase `VAD_THRESHOLD` to 0.6-0.7
2. Enable `NOISE_REDUCE`
3. Check microphone quality

### Audio Cutoff
1. Decrease `SILENCE_THRESHOLD_MS`
2. Increase `MAX_SPEECH_MS`

### Echo/Feedback
1. Use headphones
2. Enable browser echo cancellation
3. Increase physical distance between devices

## ðŸ“ API Reference

### WebSocket (`/ws`)
```typescript
// Connect
ws.send(JSON.stringify({ room: "demo", lang: "en" }));

// Send audio (Float32 PCM @ 16kHz)
ws.send(audioBuffer);

// Receive translation
{
  type: "final",
  sourceText: "à¤¨à¤®à¤¸à¥à¤¤à¥‡",
  translatedText: "Hello",
  audio: "base64...",
  sourceLang: "hi",
  targetLang: "en",
  confidence: 0.95,
  processingTime: 1.2
}
```

### Health Check (`GET /health`)
```json
{
  "status": "healthy",
  "model": "distil-large-v3",
  "device": "cuda"
}
```

## ðŸ“„ License

MIT License
